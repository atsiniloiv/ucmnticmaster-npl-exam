{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37151770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6659021",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cf8844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\efclprd\\anaconda3\\envs\\nlp2\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe  = pipeline('text-classification', model='finiteautomata/beto-sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4dac7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEG', 'score': 0.9990278482437134}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"este producto es muy malo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4763340b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POS', 'score': 0.9984679818153381}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"este producto es bueno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7aff80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POS', 'score': 0.9984679818153381},\n",
       " {'label': 'NEG', 'score': 0.9989533424377441}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"este producto es bueno\",\n",
    "    \"este producto es malo\"\n",
    "]\n",
    "pipe(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f99e5c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_classification.TextClassificationPipeline at 0x209c5d1bb50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe75305",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e31688",
   "metadata": {},
   "source": [
    "## Zero-shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd15ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "424a7ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.9192399978637695, 0.06077896058559418, 0.019981082528829575]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\n",
    "    \"This is a course about the transformers library\",\n",
    "    candidate_labels=[\"education\",\"politics\", \"business\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218573a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9eaacc",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a3b628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8734098b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to manage your budget and to create efficient, reliable, and convenient ways to support your budget and ensure that you do not have to worry about spending any more on your expenses.\\n\\n\\n\\n\\nThis course will guide you to a lot of things, including managing your budget and spending.\\nThe Basics'},\n",
       " {'generated_text': 'In this course, we will teach you how to change the rules about a person/mom, and how we can make it change. So do not just do the following to your student in the course; you may look forward to learning more about who you are and how you can move forward. The lesson will also be written on the basis of what'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    num_return_sequences=2,\n",
    "    max_length=70\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5681a1",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c024517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "150ed9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9222223,\n",
       "  'word': 'Eduardo',\n",
       "  'start': 13,\n",
       "  'end': 20},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.99872696,\n",
       "  'word': 'UCM',\n",
       "  'start': 37,\n",
       "  'end': 40},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99876946,\n",
       "  'word': 'Madrid',\n",
       "  'start': 53,\n",
       "  'end': 59}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"ner\", grouped_entities=True)\n",
    "pipe(\"Mi nombre es Eduardo y trabajo en la UCM que está en Madrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e53033",
   "metadata": {},
   "source": [
    "## QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "246fe4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.7700124382972717, 'start': 33, 'end': 36, 'answer': 'ucm'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"question-answering\")\n",
    "pipe(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Eduardo and I work at ucm in madrid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56417b11",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b229eb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Donald John Trump is the 47th president of the United States . He served as the 45th president from 2017 to 2021 . He was impeached in 2019 for abuse of power and obstruction of Congress, and in 2021 for incitement of insurrection . Trump was found guilty of falsifying business records in 2024, making him the first U.S. president convicted of a felony .'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\")\n",
    "pipe(\"\"\"\n",
    "Donald John Trump (born June 14, 1946) is an American politician, media personality, and businessman who is the 47th president of the United States. A member of the Republican Party, he served as the 45th president from 2017 to 2021.\n",
    "\n",
    "Born into a wealthy family in the New York City borough of Queens, Trump graduated from the University of Pennsylvania in 1968 with a bachelor's degree in economics. He became the president of his family's real estate business in 1971, renamed it the Trump Organization, and began acquiring and building skyscrapers, hotels, casinos, and golf courses. He launched side ventures, many licensing the Trump name, and filed for six business bankruptcies in the 1990s and 2000s. From 2004 to 2015, he hosted the reality television show The Apprentice, bolstering his fame as a billionaire. Presenting himself as a political outsider, Trump won the 2016 presidential election against Democratic Party nominee Hillary Clinton.\n",
    "\n",
    "During his first presidency, Trump imposed a travel ban on seven Muslim-majority countries, expanded the Mexico–United States border wall, and enforced a family separation policy on the border. He rolled back environmental and business regulations, signed the Tax Cuts and Jobs Act, and appointed three Supreme Court justices. In foreign policy, Trump withdrew the U.S. from agreements on climate, trade, and Iran's nuclear program, and initiated a trade war with China. In response to the COVID-19 pandemic from 2020, he downplayed its severity, contradicted health officials, and signed the CARES Act. After losing the 2020 presidential election to Joe Biden, Trump attempted to overturn the result, culminating in the January 6 Capitol attack in 2021. He was impeached in 2019 for abuse of power and obstruction of Congress, and in 2021 for incitement of insurrection; the Senate acquitted him both times.\n",
    "\n",
    "In 2023, Trump was found liable in civil cases for sexual abuse and defamation and for business fraud. He was found guilty of falsifying business records in 2024, making him the first U.S. president convicted of a felony. After winning the 2024 presidential election against Kamala Harris, he was sentenced to a penalty-free discharge, and two felony indictments against him for retention of classified documents and obstruction of the 2020 election were dismissed without prejudice. A racketeering case related to the 2020 election in Georgia is pending.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f25d1",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ee6e57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"translation\", model='Helsinki-NLP/opus-mt-es-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faf6d254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'My name is Eduardo.'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Mi nombre es Eduardo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccbf2f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.pipelines.text2text_generation.TranslationPipeline"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ac68d",
   "metadata": {},
   "source": [
    "# AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d112c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff6aa69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.distilbert.tokenization_distilbert_fast.DistilBertTokenizerFast"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37e9ebb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased-finetuned-sst-2-english', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84d22337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['este producto es bueno', 'este producto es malo']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c39bf67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 28517, 4031, 2080, 9686, 20934, 16515, 102], [101, 28517, 4031, 2080, 9686, 15451, 2080, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = tokenizer.tokenize(sentences)\n",
    "tokenizer.convert_tokens_to_ids(tokenized)\n",
    "ids = tokenizer.encode(sentences)\n",
    "tokenizer.decode(ids)\n",
    "tokenizer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "186514a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "          2607,  2026,  2878,  2166,  1012,   102],\n",
       "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"I've been waiting for a Huggingface course my whole life.\",\n",
    "    \"I hate this so much!\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841cd359",
   "metadata": {},
   "source": [
    "# AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc16688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c944df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): DistilBertSdpaAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ab472",
   "metadata": {},
   "source": [
    "## AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab2a2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47957e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.attention_dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed926118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed080c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModel.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b29ffdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "200e87d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[-0.1798,  0.2333,  0.6321,  ..., -0.3017,  0.5008,  0.1481],\n",
       "         [ 0.2758,  0.6497,  0.3200,  ..., -0.0760,  0.5136,  0.1329],\n",
       "         [ 0.9046,  0.0985,  0.2950,  ...,  0.3352, -0.1407, -0.6464],\n",
       "         ...,\n",
       "         [ 0.1466,  0.5661,  0.3235,  ..., -0.3376,  0.5100, -0.0561],\n",
       "         [ 0.7500,  0.0487,  0.1738,  ...,  0.4684,  0.0030, -0.6084],\n",
       "         [ 0.0519,  0.3729,  0.5223,  ...,  0.3584,  0.6500, -0.3883]],\n",
       "\n",
       "        [[-0.2937,  0.7283, -0.1497,  ..., -0.1187, -1.0227, -0.0422],\n",
       "         [-0.2206,  0.9384, -0.0951,  ..., -0.3643, -0.6605,  0.2407],\n",
       "         [-0.1536,  0.8988, -0.0728,  ..., -0.2189, -0.8528,  0.0710],\n",
       "         ...,\n",
       "         [-0.3017,  0.9002, -0.0200,  ..., -0.1082, -0.8412, -0.0861],\n",
       "         [-0.3338,  0.9674, -0.0729,  ..., -0.1952, -0.8181, -0.0634],\n",
       "         [-0.3454,  0.8824, -0.0426,  ..., -0.0993, -0.8329, -0.1065]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a71e5bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state = outputs.last_hidden_state\n",
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f7333f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.17977962,  0.23332772,  0.6320998 , ..., -0.30166614,\n",
       "          0.5008202 ,  0.14814308],\n",
       "        [ 0.2757772 ,  0.64971167,  0.31997764, ..., -0.0759954 ,\n",
       "          0.51361716,  0.13292125],\n",
       "        [ 0.90458596,  0.09851333,  0.29497284, ...,  0.3351953 ,\n",
       "         -0.1407413 , -0.6464039 ],\n",
       "        ...,\n",
       "        [ 0.14658983,  0.5660593 ,  0.32352832, ..., -0.3375748 ,\n",
       "          0.5099788 , -0.05610962],\n",
       "        [ 0.7500047 ,  0.04872601,  0.17380042, ...,  0.46841565,\n",
       "          0.0029665 , -0.6083766 ],\n",
       "        [ 0.05194494,  0.37294793,  0.52233267, ...,  0.35840583,\n",
       "          0.65004313, -0.38829845]],\n",
       "\n",
       "       [[-0.2937065 ,  0.72825634, -0.14972717, ..., -0.11868107,\n",
       "         -1.0226725 , -0.04215725],\n",
       "        [-0.22063631,  0.9383849 , -0.09512513, ..., -0.36431676,\n",
       "         -0.660522  ,  0.24069716],\n",
       "        [-0.15360813,  0.89875025, -0.07276463, ..., -0.21891764,\n",
       "         -0.8527593 ,  0.0709941 ],\n",
       "        ...,\n",
       "        [-0.30174723,  0.9002209 , -0.01995075, ..., -0.10816886,\n",
       "         -0.8412145 , -0.0861436 ],\n",
       "        [-0.33384174,  0.96742505, -0.07294402, ..., -0.19517353,\n",
       "         -0.81813234, -0.06339071],\n",
       "        [-0.34538   ,  0.8823622 , -0.04263914, ..., -0.09926435,\n",
       "         -0.8328665 , -0.1064744 ]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_state = last_hidden_state.cpu().numpy()\n",
    "    \n",
    "last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c724f15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16, 768)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b35ea89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 768)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f108ffbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548968f5",
   "metadata": {},
   "source": [
    "# Ejercicio (clasificación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a50d0c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nunca llego el pedido y el vendedor pasa de to...</td>\n",
       "      <td>No llego nunca</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>no sé como es, porque debería haber llegado ay...</td>\n",
       "      <td>Todavía no ha llegado</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>guantes cómodos, no lo niego, pero de mala cal...</td>\n",
       "      <td>Guantes de baja calidad</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hasta hoy no he visto el producto. el pedido h...</td>\n",
       "      <td>Muy Mala experiencia</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>no puedo valorarla porque, después de casi una...</td>\n",
       "      <td>Paquete perdido?</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                        review_body  \\\n",
       "0      1  nunca llego el pedido y el vendedor pasa de to...   \n",
       "1      1  no sé como es, porque debería haber llegado ay...   \n",
       "2      1  guantes cómodos, no lo niego, pero de mala cal...   \n",
       "3      1  hasta hoy no he visto el producto. el pedido h...   \n",
       "4      1  no puedo valorarla porque, después de casi una...   \n",
       "\n",
       "              review_title product_category  \n",
       "0           No llego nunca           sports  \n",
       "1    Todavía no ha llegado           sports  \n",
       "2  Guantes de baja calidad           sports  \n",
       "3     Muy Mala experiencia           sports  \n",
       "4         Paquete perdido?           sports  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/eduardofc/data/main/amazon_sports.csv\")\n",
    "df['review_body'] = df['review_body'].str.replace(\"[^a-zA-ZñÑáéíóú .,]\", \"\", regex=True)\n",
    "df['review_body'] = df['review_body'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e5a4084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good_product\n",
       "0    2438\n",
       "1    2512\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.stars != 2]\n",
    "df = df[df.stars != 3]\n",
    "df = df[df.stars != 4]\n",
    "\n",
    "df['good_product'] = (df.stars > 3).astype(int)\n",
    "\n",
    "df.groupby('good_product').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3ddd15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) modelo\n",
    "model_id = 'distilbert/distilbert-base-uncased-finetuned-sst-2-english'\n",
    "\n",
    "# 2) preparamos modelo y tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63343f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df['review_body'].values)\n",
    "y = df['good_product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d292a9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 16634,  3540,  ...,     0,     0,     0],\n",
       "        [  101,  2053,  7367,  ...,     0,     0,     0],\n",
       "        [  101, 19739, 24985,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  4206,  2319,  ...,     0,     0,     0],\n",
       "        [  101, 24970, 15781,  ...,     0,     0,     0],\n",
       "        [  101,  2064,  9386,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_inputs = tokenizer(X, padding=True, truncation=True, return_tensors='pt')\n",
    "X_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5286b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_outputs = model(**X_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cb87db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x):\n",
    "    inputs = tokenizer(x, padding=True, truncation=True, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = last_hidden_state.cpu().numpy()\n",
    "    return last_hidden_state[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af4cc28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 24min 32s\n",
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "last_layer_model = df['review_body'].map(forward_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "006b7d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4950,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb9c29f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer_model[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb7e76ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_758</th>\n",
       "      <th>f_759</th>\n",
       "      <th>f_760</th>\n",
       "      <th>f_761</th>\n",
       "      <th>f_762</th>\n",
       "      <th>f_763</th>\n",
       "      <th>f_764</th>\n",
       "      <th>f_765</th>\n",
       "      <th>f_766</th>\n",
       "      <th>f_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.148120</td>\n",
       "      <td>-0.379483</td>\n",
       "      <td>0.762809</td>\n",
       "      <td>-0.557681</td>\n",
       "      <td>-0.130396</td>\n",
       "      <td>1.108286</td>\n",
       "      <td>1.687660</td>\n",
       "      <td>0.959550</td>\n",
       "      <td>1.121630</td>\n",
       "      <td>-0.174720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189335</td>\n",
       "      <td>-0.601361</td>\n",
       "      <td>0.639028</td>\n",
       "      <td>-0.962111</td>\n",
       "      <td>0.088468</td>\n",
       "      <td>-0.441341</td>\n",
       "      <td>0.572124</td>\n",
       "      <td>-0.472088</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>1.043632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.571195</td>\n",
       "      <td>0.654400</td>\n",
       "      <td>-0.146572</td>\n",
       "      <td>-0.371740</td>\n",
       "      <td>-0.561087</td>\n",
       "      <td>0.482954</td>\n",
       "      <td>0.573449</td>\n",
       "      <td>1.367549</td>\n",
       "      <td>0.715778</td>\n",
       "      <td>-0.132606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904775</td>\n",
       "      <td>0.101262</td>\n",
       "      <td>-0.045985</td>\n",
       "      <td>-0.905033</td>\n",
       "      <td>0.343865</td>\n",
       "      <td>-0.559881</td>\n",
       "      <td>0.769444</td>\n",
       "      <td>-0.414418</td>\n",
       "      <td>-0.041818</td>\n",
       "      <td>0.411064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.767859</td>\n",
       "      <td>-0.032666</td>\n",
       "      <td>0.192588</td>\n",
       "      <td>-0.222683</td>\n",
       "      <td>-0.234021</td>\n",
       "      <td>0.034018</td>\n",
       "      <td>0.298249</td>\n",
       "      <td>0.913226</td>\n",
       "      <td>0.543267</td>\n",
       "      <td>-0.024575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860801</td>\n",
       "      <td>-0.422094</td>\n",
       "      <td>0.225442</td>\n",
       "      <td>-1.015883</td>\n",
       "      <td>0.652911</td>\n",
       "      <td>0.123236</td>\n",
       "      <td>-0.053870</td>\n",
       "      <td>-0.334967</td>\n",
       "      <td>0.125810</td>\n",
       "      <td>0.478331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.191025</td>\n",
       "      <td>0.593415</td>\n",
       "      <td>0.110412</td>\n",
       "      <td>-0.693767</td>\n",
       "      <td>-0.555686</td>\n",
       "      <td>0.283406</td>\n",
       "      <td>0.834452</td>\n",
       "      <td>1.027178</td>\n",
       "      <td>0.514113</td>\n",
       "      <td>-0.352057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807701</td>\n",
       "      <td>-0.201013</td>\n",
       "      <td>0.141311</td>\n",
       "      <td>-0.729934</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>-0.474524</td>\n",
       "      <td>0.901508</td>\n",
       "      <td>-0.185042</td>\n",
       "      <td>-0.411359</td>\n",
       "      <td>0.675568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.521726</td>\n",
       "      <td>0.500266</td>\n",
       "      <td>0.016186</td>\n",
       "      <td>-0.287753</td>\n",
       "      <td>-0.563475</td>\n",
       "      <td>0.629885</td>\n",
       "      <td>0.500428</td>\n",
       "      <td>0.971674</td>\n",
       "      <td>0.615660</td>\n",
       "      <td>0.037409</td>\n",
       "      <td>...</td>\n",
       "      <td>1.359321</td>\n",
       "      <td>-0.025231</td>\n",
       "      <td>-0.190737</td>\n",
       "      <td>-1.132495</td>\n",
       "      <td>0.245646</td>\n",
       "      <td>-0.599195</td>\n",
       "      <td>0.629616</td>\n",
       "      <td>-0.078504</td>\n",
       "      <td>-0.116343</td>\n",
       "      <td>0.992917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
       "0 -0.148120 -0.379483  0.762809 -0.557681 -0.130396  1.108286  1.687660   \n",
       "1 -0.571195  0.654400 -0.146572 -0.371740 -0.561087  0.482954  0.573449   \n",
       "2 -0.767859 -0.032666  0.192588 -0.222683 -0.234021  0.034018  0.298249   \n",
       "3 -0.191025  0.593415  0.110412 -0.693767 -0.555686  0.283406  0.834452   \n",
       "4 -0.521726  0.500266  0.016186 -0.287753 -0.563475  0.629885  0.500428   \n",
       "\n",
       "        f_7       f_8       f_9  ...     f_758     f_759     f_760     f_761  \\\n",
       "0  0.959550  1.121630 -0.174720  ...  0.189335 -0.601361  0.639028 -0.962111   \n",
       "1  1.367549  0.715778 -0.132606  ...  0.904775  0.101262 -0.045985 -0.905033   \n",
       "2  0.913226  0.543267 -0.024575  ...  0.860801 -0.422094  0.225442 -1.015883   \n",
       "3  1.027178  0.514113 -0.352057  ...  0.807701 -0.201013  0.141311 -0.729934   \n",
       "4  0.971674  0.615660  0.037409  ...  1.359321 -0.025231 -0.190737 -1.132495   \n",
       "\n",
       "      f_762     f_763     f_764     f_765     f_766     f_767  \n",
       "0  0.088468 -0.441341  0.572124 -0.472088  0.042865  1.043632  \n",
       "1  0.343865 -0.559881  0.769444 -0.414418 -0.041818  0.411064  \n",
       "2  0.652911  0.123236 -0.053870 -0.334967  0.125810  0.478331  \n",
       "3  0.017483 -0.474524  0.901508 -0.185042 -0.411359  0.675568  \n",
       "4  0.245646 -0.599195  0.629616 -0.078504 -0.116343  0.992917  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_X = pd.DataFrame(last_layer_model.to_list(), columns=[f\"f_{i}\" for i in range(768)])\n",
    "pd_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a27b353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd_X\n",
    "y = df.good_product\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a3958bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3960"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a5231345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0133ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8313131313131313"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=99)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9371e4a",
   "metadata": {},
   "source": [
    "# Automodel for sequence classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00a98666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I've been waiting for a Huggingface course my whole life.\",\n",
       " 'I hate this so much!']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9da364f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distilbert/distilbert-base-uncased-finetuned-sst-2-english'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "250c6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8a4f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d18aa8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2026,  2878,  2166,  1012,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51dd6dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n",
      "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "338d50d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5607,  1.6123],\n",
       "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f7e83ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0195e-02, 9.5980e-01],\n",
      "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab2bf582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515996bd",
   "metadata": {},
   "source": [
    "# All together in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c287afa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = 'distilbert/distilbert-base-uncased-finetuned-sst-2-english'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, padding=True, truncation=True, return_tensors=)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    task = \"text-classification\",\n",
    "    model = model,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e868db9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdcb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fae27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b65677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from keras import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd40a54",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bcb4c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hope you're not alone.</td>\n",
       "      <td>Espero que no estés solo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I was taking a bath, the telephone rang.</td>\n",
       "      <td>Mientras me bañaba, sonó el teléfono.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I just need you to come with me.</td>\n",
       "      <td>Solo necesito que vengas conmigo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tom wondered how soon Mary would have dinner r...</td>\n",
       "      <td>Tom se preguntaba cuán pronto María tendría li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tom is waiting for an answer.</td>\n",
       "      <td>Tom está esperando una respuesta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en                                                 es\n",
       "0                           I hope you're not alone.                          Espero que no estés solo.\n",
       "1      When I was taking a bath, the telephone rang.              Mientras me bañaba, sonó el teléfono.\n",
       "2                   I just need you to come with me.                  Solo necesito que vengas conmigo.\n",
       "3  Tom wondered how soon Mary would have dinner r...  Tom se preguntaba cuán pronto María tendría li...\n",
       "4                      Tom is waiting for an answer.                  Tom está esperando una respuesta."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/eduardofc/data/main/es_en.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27e35501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spanish\n",
    "es_sentences = df.es.values\n",
    "es_tokenizer = Tokenizer()\n",
    "es_tokenizer.fit_on_texts(es_sentences)\n",
    "es_sequences = es_tokenizer.texts_to_sequences(es_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a44798c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# english\n",
    "en_sentences = df.en.values\n",
    "en_tokenizer = Tokenizer()\n",
    "en_tokenizer.fit_on_texts(en_sentences)\n",
    "en_sequences = en_tokenizer.texts_to_sequences(en_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca6fe6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 | 25\n"
     ]
    }
   ],
   "source": [
    "es_length = max([len(ss) for ss in es_sequences])\n",
    "en_length = max([len(ss) for ss in en_sequences])\n",
    "\n",
    "print(f\"{es_length} | {en_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "344b726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7893 | 5053\n"
     ]
    }
   ],
   "source": [
    "es_vocab = len(es_tokenizer.word_index) +1\n",
    "en_vocab = len(en_tokenizer.word_index) +1\n",
    "\n",
    "print(f\"{es_vocab} | {en_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e773139",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_padded = pad_sequences(es_sequences, maxlen=es_length, truncating='post')\n",
    "en_padded = pad_sequences(en_sequences, maxlen=en_length, truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5128ed2b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccfdf68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\efclprd\\anaconda3\\envs\\nlp1\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(812)\n",
    "\n",
    "embed_dim = 128\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=es_vocab,\n",
    "        input_length=es_length,\n",
    "        output_dim=embed_dim\n",
    "    ),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    RepeatVector(en_length),\n",
    "    LSTM(64, return_sequences=True, dropout=.2),\n",
    "    TimeDistributed(Dense(en_vocab, activation='softmax'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75d0c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=sparse_categorical_crossentropy,\n",
    "    optimizer=Adam(1e-3), \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3881d268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 31, 128)           1010304   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVecto  (None, 25, 64)            0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 25, 64)            33024     \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 25, 5053)          328445    \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1421181 (5.42 MB)\n",
      "Trainable params: 1421181 (5.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c78a30dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "WARNING:tensorflow:From C:\\Users\\efclprd\\anaconda3\\envs\\nlp1\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\efclprd\\anaconda3\\envs\\nlp1\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "313/313 [==============================] - 25s 69ms/step - loss: 2.8938 - accuracy: 0.7462\n",
      "Epoch 2/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1815 - accuracy: 0.7502\n",
      "Epoch 3/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1802 - accuracy: 0.7502\n",
      "Epoch 4/35\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 2.1798 - accuracy: 0.7502\n",
      "Epoch 5/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1795 - accuracy: 0.7502\n",
      "Epoch 6/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1792 - accuracy: 0.7502\n",
      "Epoch 7/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1790 - accuracy: 0.7502\n",
      "Epoch 8/35\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 2.1784 - accuracy: 0.7502\n",
      "Epoch 9/35\n",
      "313/313 [==============================] - 21s 69ms/step - loss: 2.1783 - accuracy: 0.7502\n",
      "Epoch 10/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1782 - accuracy: 0.7502\n",
      "Epoch 11/35\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 2.1779 - accuracy: 0.7502\n",
      "Epoch 12/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1775 - accuracy: 0.7502\n",
      "Epoch 13/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1768 - accuracy: 0.7502\n",
      "Epoch 14/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1765 - accuracy: 0.7502\n",
      "Epoch 15/35\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 2.1762 - accuracy: 0.7502\n",
      "Epoch 16/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1757 - accuracy: 0.7502\n",
      "Epoch 17/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1750 - accuracy: 0.7502\n",
      "Epoch 18/35\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 2.1745 - accuracy: 0.7502\n",
      "Epoch 19/35\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 2.1737 - accuracy: 0.7502\n",
      "Epoch 20/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1733 - accuracy: 0.7502\n",
      "Epoch 21/35\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 2.1713 - accuracy: 0.7502\n",
      "Epoch 22/35\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 2.1625 - accuracy: 0.7502\n",
      "Epoch 23/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1533 - accuracy: 0.7502\n",
      "Epoch 24/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1434 - accuracy: 0.7502\n",
      "Epoch 25/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 2.1254 - accuracy: 0.7502\n",
      "Epoch 26/35\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 2.1061 - accuracy: 0.7502\n",
      "Epoch 27/35\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 2.0388 - accuracy: 0.7502\n",
      "Epoch 28/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 1.7936 - accuracy: 0.7502\n",
      "Epoch 29/35\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 1.6712 - accuracy: 0.7536\n",
      "Epoch 30/35\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 1.6265 - accuracy: 0.7573\n",
      "Epoch 31/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 1.6022 - accuracy: 0.7581\n",
      "Epoch 32/35\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 1.5847 - accuracy: 0.7592\n",
      "Epoch 33/35\n",
      "313/313 [==============================] - 21s 69ms/step - loss: 1.5677 - accuracy: 0.7605\n",
      "Epoch 34/35\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 1.5536 - accuracy: 0.7616\n",
      "Epoch 35/35\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 1.5414 - accuracy: 0.7630\n",
      ">>>> Elapsed time: 12.595557185014089m\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "model.fit(\n",
    "    es_padded,\n",
    "    en_padded,\n",
    "    epochs=35\n",
    ")\n",
    "\n",
    "end = time()\n",
    "print(f\">>>> Elapsed time: {(end-start)/60}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "980c0992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\efclprd\\anaconda3\\envs\\nlp1\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model_seq2seq35.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8ac9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# model2 = load_model(\"model_seq2seq35.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2148a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model_seqseq2_500.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3294753f",
   "metadata": {},
   "source": [
    "# Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1cce1580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debes dar lo mejor.\n",
      "You must do your best.\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'you must do your best'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii = 457\n",
    "# ii = 841\n",
    "\n",
    "print(f\"{es_sentences[ii]}\")\n",
    "print(f\"{en_sentences[ii]}\")\n",
    "\n",
    "preds = model.predict(es_padded[ii:ii+1])[0]\n",
    "' '.join([en_tokenizer.index_word[ww] for ww in np.argmax(preds, 1) if ww!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c9263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35ad86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac7f671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
